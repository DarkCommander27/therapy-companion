# CareBridge Companion Environment Configuration
# Copy this file to .env and update with your facility's values

# ========================================
# Server Configuration
# ========================================
NODE_ENV=development
PORT=3000
HOST=localhost

# ========================================
# Database
# ========================================
MONGODB_URI=mongodb://localhost:27017/carebridge-companion
MONGODB_USERNAME=
MONGODB_PASSWORD=

# ========================================
# JWT & Authentication
# ========================================
JWT_SECRET=your-super-secret-jwt-key-change-in-production
JWT_EXPIRATION=7d
REFRESH_TOKEN_SECRET=your-super-secret-refresh-token-key

# ========================================
# Email Configuration (for briefing notifications)
# ========================================
EMAIL_SERVICE=gmail
EMAIL_USER=your-email@gmail.com
EMAIL_PASSWORD=your-app-specific-password
EMAIL_FROM_NAME=CareBridge Companion
EMAIL_SUPPORT=support@your-facility.org

# ========================================
# NLU & ML Models
# ========================================
# Path to local inference models (privacy-first)
NLU_MODELS_PATH=./models
INTENT_MODEL_PATH=./models/intent-recognition
EMOTION_MODEL_PATH=./models/emotion-detection
USE_LOCAL_INFERENCE=true

# Remote model API (optional fallback, not recommended for privacy)
NLU_API_URL=
NLU_API_KEY=

# ========================================
# HEALTH CHECK & MONITORING
# ========================================
# Enable periodic health checks for services (database, model, etc)
ENABLE_HEALTH_CHECK=true

# ========================================
# LLAMA 3.1 LOCAL MODEL INTEGRATION
# ========================================
# Local Llama 3.1 model via Ollama for AI companion chat
#
# SETUP INSTRUCTIONS:
# 1. Install Ollama: https://ollama.ai
# 2. Download model: ollama pull llama2:7b
# 3. Start Ollama: ollama serve
# 4. Verify model loaded: curl http://localhost:11434/api/tags
#
# THEN enable and configure below:

LLAMA_ENABLED=true
LLAMA_API_URL=http://localhost:11434
LLAMA_MODEL=llama2:7b
LLAMA_TIMEOUT=30000
LLAMA_TEMPERATURE=0.7
LLAMA_MAX_TOKENS=500
LLAMA_CONTEXT_WINDOW=2048

# Streaming responses (real-time)
# true = stream responses as generated (better UX, faster perceived response)
# false = wait for complete response (simpler, slower)
LLAMA_STREAM=true

# Rate limiting for model calls (prevent abuse)
LLAMA_RATE_LIMIT=10
LLAMA_RATE_LIMIT_WINDOW=60000

# ========================================
# Safety & Alert Configuration
# ========================================
# Semi-colon separated list of alert recipients (email)
SAFETY_ALERT_RECIPIENTS=clinician@facility.org;supervisor@facility.org
SAFEGUARDING_ALERT_RECIPIENTS=safeguarding@facility.org

# Alert severity thresholds
CRITICAL_ALERT_THRESHOLD=0.9
HIGH_ALERT_THRESHOLD=0.7
MEDIUM_ALERT_THRESHOLD=0.5

# Response time SLA (minutes)
ALERT_RESPONSE_SLA=15

# ========================================
# Facility Information
# ========================================
FACILITY_NAME=Your Facility Name
FACILITY_STATE=WV
FACILITY_TIMEZONE=America/New_York
MANDATORY_REPORTER_CONTACT=reporter@facility.org

# ========================================
# Rate Limiting
# ========================================
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100
COMPANION_CHAT_RATE_LIMIT_MAX=50

# ========================================
# Logging
# ========================================
LOG_LEVEL=info
LOG_DIR=./logs
ENABLE_REQUEST_LOGGING=true
ENABLE_AUDIT_LOGGING=true

# ========================================
# Data Retention
# ========================================
CONVERSATION_RETENTION_DAYS=90
BRIEFING_RETENTION_DAYS=365
INCIDENT_LOG_RETENTION_DAYS=730
AUDIT_LOG_RETENTION_DAYS=365

# ========================================
# Feature Flags
# ========================================
ENABLE_TRANSCRIPT_EXPORT=false
ENABLE_BREAK_GLASS_ACCESS=false
ENABLE_HEALTH_CHECK=true

# ========================================
# Development & Debugging
# ========================================
DEBUG=carebridge-companion:*
MOCK_EMAIL=false
MOCK_NLU=false
